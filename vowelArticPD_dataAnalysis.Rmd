---
title: "Vowel Artic in PD: Bayesian Analysis"
output: html_notebook
---

# Packages
```{r}
library(tidyverse)
library(ggrepel)
library(extraDistr)   # install.packages("extraDistr")
library(HDInterval)   # install.packages("HDInterval")
library(tidybayes)    # install.packages("tidybayes")
library(bayesplot)    # install.packages("bayesplot")
library(modelr)
library(broom.mixed)  # install.packages("broom.mixed")
library(brms)         # install.packages("brms")
library(ggthemes)
library(patchwork)
library(weights)
theme_set(theme_minimal())

# Creating a theme function used for visualizations
theme_clean <- function() {
  theme_minimal(base_family = "Arial") +
    theme(panel.grid.minor = element_blank(),
          plot.title = element_text(face = "bold"),
          axis.title = element_text(face = "bold"),
          strip.text = element_text(face = "bold", size = rel(1), hjust = 0),
          strip.background = element_rect(fill = "grey80", color = NA),
          legend.title = element_text(face = "bold"))
}
```

# Background
	
This study is a follow-up analysis of our previous work examining the predictive value of acoustic and kinematic measures in predicting intelligibility and articulatory precision in speakers with and without Parkinson's disease (PD; https://osf.io/hfuq5/). 

Our previous findings indicated that among several measures, vowel space area (VSA), and kinematic distance were the best predictors of both intelligibility and articulatory precision. However, this relationship was examined using pooled data, without considering differences in speaking group (control vs. PD) or condition (conversational vs. clear). Therefore, it remains unknown how speakers with and without dysarthria due to PD differ in terms of intelligibility, articulatory precision, VSA, and kinematic distance. Additionally, it is unclear how these groups respond to prompts to speak more clearly. Thus, the following research questions were posed:

1. How do speakers with and without PD of varying dysarthria severity levels differ in terms of intelligibility, articulatory precision, vowel space area (VSA), and kinematic distance? (Group Effects)
2. When prompted to speak more clearly, how do speakers with and without PD of varying dysarthria severities modify their articulation (VSA and kinematic distance), and does this cue result in perceptual gains in intelligibility and articulatory precision? (Group × Condition Interaction Effects)


# Data Analysis
Before we can build our models, we'll need some information about the speakers.
```{r}
speakerList <-
  rio::import(file = "https://raw.githubusercontent.com/AustinRThompson/multidomain-vowelArtic-PD/main/Data/PreppedData/Speaker%20List_Clean.csv") %>%
  
  # Making sure dxTime is numeric
  dplyr::mutate(dxTime = as.numeric(dxTime)) %>%
  
  # Refactoring Sex
  dplyr::mutate(Sex = factor(
    Sex,
    levels = c("M",
               "F"),
    labels = c("Male Speakers",
               "Female Speakers")
  )) %>%
  
  # Removing the MoCA Scores - Not all speakers had them
  dplyr::select(!MoCA)
```

## Intelligibility
Intelligibility was collected through ratings obtained through a listener survey. They would listen to a speaker, and then rate how intelligible the speaker was using a horizontally oriented visual analog scale. The left end of the scale was labeled "Cannot understand anything" and corresponded to a value of 0. The right end of the scale was labeled "Understood everything" and corresponded to a value of 100.

While any value between 0 and 100 could be selected, listeners tended to rate on the extreme ends, resulting in a beta distribution. Therefore, for this model, we used a beta family for our model. But first, we rescaled the intelligibility measure to fall between 0 and 1, excluding the endpoint values of 0 and 1.
### Loading the data
```{r}
perceptualMeasures <- rio::import(file = "https://raw.githubusercontent.com/AustinRThompson/multidomain-vowelArtic-PD/main/Data/PreppedData/ListenerData/ListenerRatings_allRatings.csv") %>%
  dplyr::select(!V1) %>%
  dplyr::filter(ratingType == "Int") %>% # We only want the intelligibility ratings for this model
  dplyr::filter(condition != "lessClear") %>% # We won't use the less clear condition in this study
  
  # Here we rename some variables and clean up the factors
  dplyr::rename(Int = Rating) %>%
  dplyr::mutate(Sex = factor(Sex, levels = c("M", "F")),
                condition = factor(condition, levels = c("conv", "moreClear"))) %>%
  
  # Now we merge the intelligibility ratings with the speakerList, which has information about severity level.
  base::merge(., speakerList %>%
                dplyr::select(StudyID, Severity)) %>%
  dplyr::mutate(
    Severity = factor(
      Severity,
      levels = c("HC", "Mild", "Moderate", "Severe", "Profound"),
      labels = c("Control", "Mild", "Moderate", "Severe", "Profound")
    )
  ) %>%
  dplyr::relocate(Severity, .after = Group)

# Lets visualize the outcome measure, intelligibility
hist(perceptualMeasures$Int)

# Here, we rescale the measure to fit a beta distribtion
epsilon <- 1e-5
data_modelData_Int <- perceptualMeasures %>%
  dplyr::select(StudyID,
                Group,
                Sex,
                Age,
                Severity,
                condition,
                Sent,
                rep,
                ListenerID,
                Int) %>%
  dplyr::mutate(
    Int = Int / 100,
    # the following makes sure that 0 and 1 are not included in the beta distribution
    Int = Int * ((nrow(.) - 1) + .5) / nrow(.),
    Int = Int * (1 - 2 * epsilon) + epsilon
  )

performance::check_distribution(data_modelData_Int$Int)

# Taking out the trash
rm(perceptualMeasures, epsilon)
```

### Priors
First, we need to figure out the model parameters
```{r}

modelFormula_Int <-
  Int ~ Severity * condition +
  (1 | StudyID) + # Each Speaker (StudyID) read three sentences (Sent) five times each (rep).
  (1 | ListenerID)

brms::get_prior(
  modelFormula_Int, 
  data = data_modelData_Int, 
  family = Beta)
```
Now we can specify weakly informative priors.
```{r}
prior_Int <- c(
  prior(normal(0, 10), class = Intercept), # start with larger value - 10
  prior(normal(0, 10), class = b),
  prior(cauchy(0, 10), class = sd), # paper on variance priors: https://projecteuclid.org/journals/bayesian-analysis/volume-1/issue-3/Prior-distributions-for-variance-parameters-in-hierarchical-models-comment-on/10.1214/06-BA117A.full - check 95% interval for cauchy - very large upper bound 10
  prior(gamma(1, 0.5), class = phi) # Phi = 1, mu = .5
)
```

### Building the model
```{r}
model_Int <- brms::brm(
  formula = modelFormula_Int,
  data = data_modelData_Int,
  prior = prior_Int,
  family = Beta,
  chains = 4,
  cores = 4,
  iter = 4000,
  warmup = 1000,
  control = list(adapt_delta = 0.95),
  file = "Models/brms_Int.rds",
  file_refit = "on_change"
)

# Calculating the residual variance
if (file.exists("Models/variance_Int.rds") == T) {
  variance_Int <- base::readRDS(file = "Models/variance_Int.rds")
} else {
  variance_Int <- insight::get_variance(model_Int)
  base::saveRDS(variance_Int, file = "Models/variance_Int.rds")
}
```

### Model Summary
```{r}
# Probability of direction (pd)
pd_Int <- bayestestR::p_direction(model_Int) %>%
  dplyr::rename(term = Parameter,
                effect = Effects,
                component = Component) %>%
  dplyr::mutate(
    component = ifelse(component == "conditional", "cond", component),
    term = gsub(pattern = "b_", replacement = "", term),
    term = ifelse(term == "Intercept", "(Intercept)", term))

# Model results
modelSummary_Int <- tidy(model_Int) %>%
  dplyr::rename(l_95_CI = conf.low,
                u_95_CI = conf.high) %>%
  dplyr::mutate(order = row_number()) %>%
  base::merge(.,pd_Int, all = T) %>%
  dplyr::arrange(order) %>%
  dplyr::select(!order) %>%
  dplyr::mutate(
    estimate_natScale = plogis(estimate),
    l_95_CI_natScale = plogis(l_95_CI),
    u_95_CI_natScale = plogis(u_95_CI),
    robust = case_when(
      as.integer(!(l_95_CI <= 0 & u_95_CI > 0)) == 1 & pd > .95 ~ "robust",
      TRUE ~ "not robust"
    )
  )

rm(pd_Int)
```

### Pairwise Comparisons
```{r}

# Probability of direction (pd)
pd_emmeans_Int <- bayestestR::p_direction(
  model_Int %>%
    emmeans::emmeans(
      ~ condition | Severity,
      epred = TRUE,
      re_formula = NA,
    ) %>%
    emmeans::contrast(method = "revpairwise")
) |>
  as.data.frame() %>%
  dplyr::mutate(Severity = gsub(pattern = "moreClear - conv ", replacement = "", Parameter)) %>%
  as.data.frame() |>
  dplyr::select(!Parameter)


emmeans_Int <- model_Int %>%
  emmeans::emmeans(~ condition | Severity,
                   epred = TRUE,
                   re_formula = NA,) %>%
  emmeans::contrast(method = "revpairwise") %>%
  tidy() |>
  dplyr::rename(l_95_HPD = lower.HPD,
                u_95_HPD = upper.HPD) %>%
  dplyr::mutate(order = row_number()) %>%
  base::merge(., pd_emmeans_Int) |>
  dplyr::arrange(order) %>%
  dplyr::select(!order) %>%
  dplyr::mutate(
    robust = case_when(
      as.integer(!(l_95_HPD <= 0 & u_95_HPD > 0)) == 1 & pd > .95 ~ "robust",
      TRUE ~ "not robust"
    ),
    writeUp = paste0("β=",rd(estimate, digits = 2),", 95% HPD Interval = [",
                     rd(l_95_HPD, digits = 2), ", ",
                     rd(u_95_HPD, digits = 2), "]")
  )

rm(pd_emmeans_Int)
```


### Model Diagnostics
```{r}
# Assess chain mixing
plot_chainMix_Int <- base::plot(model_Int, ask=FALSE)

# Posterior predictive check
plot_ppCheck_Int <- brms::pp_check(model_Int, ndraws = 1000)

# Plot conditional effects
plot_conditionalEffects_Int <- base::plot(conditional_effects(model_Int), ask = FALSE)

# Interval Estimations
data_posterior_Int <- as.matrix(model_Int) %>%
  as.data.frame()

plot_intervalEst_Int <- mcmc_areas(
  data_posterior_Int,
  pars = fixed_effects <- data_posterior_Int %>%
    as.data.frame() %>%
    dplyr::select(starts_with("b_")) %>%
    colnames(),
  # arbitrary threshold for shading probability mass
  prob = 0.95
) 

```

## Articulatory Precision
Articulatory precision was collected in the same way as intelligibility ratings. They were collected through ratings obtained through a listener survey. They would listen to a speaker, and then rate how precise the speaker was using a horizontally oriented visual analog scale. The left end of the scale was labeled "imprecise or mumbled" and corresponded to a value of 0. The right end of the scale was labeled "precise or clear" and corresponded to a value of 100.

While any value between 0 and 100 could be selected, listeners tended to rate on the extreme ends, resulting in a beta distribution. Therefore, for this model, we used a beta family for our model. But first, we rescaled the precision ratings to fall between 0 and 1, excluding the endpoint values of 0 and 1.

### Loading the data
```{r}
perceptualMeasures <- rio::import(file = "https://raw.githubusercontent.com/AustinRThompson/multidomain-vowelArtic-PD/main/Data/PreppedData/ListenerData/ListenerRatings_allRatings.csv") %>%
  dplyr::select(!V1) %>%
  dplyr::filter(ratingType == "AP") %>% # We only want the intelligibility ratings for this model
  dplyr::filter(condition != "lessClear") %>% # We won't use the less clear condition in this study
  
  # Here we rename some variables and clean up the factors
  dplyr::rename(AP = Rating) %>%
  dplyr::mutate(Sex = factor(Sex, levels = c("M", "F")),
                condition = factor(condition, levels = c("conv", "moreClear"))) %>%
  
  # Now we merge the intelligibility ratings with the speakerList, which has information about severity level.
  base::merge(., speakerList %>%
                dplyr::select(StudyID, Severity)) %>%
  dplyr::mutate(
    Severity = factor(
      Severity,
      levels = c("HC", "Mild", "Moderate", "Severe", "Profound"),
      labels = c("Control", "Mild", "Moderate", "Severe", "Profound")
    )
  ) %>%
  dplyr::relocate(Severity, .after = Group)


# Lets visualize the outcome measure, intelligibility
hist(perceptualMeasures$AP)

# Here, we rescale the measure to fit a beta distribtion
epsilon <- 1e-5
data_modelData_AP <- perceptualMeasures %>%
  dplyr::select(StudyID,
                Group,
                Sex,
                Age,
                Severity,
                condition,
                Sent,
                rep,
                ListenerID,
                AP) %>%
  dplyr::mutate(
    AP = AP / 100,
    AP = AP * ((nrow(.) - 1) + .5) / nrow(.),
    AP = AP * (1 - 2 * epsilon) + epsilon
  ) # this makes sure that 0 and 1 are not included in the beta distribution

performance::check_distribution(data_modelData_AP$AP)

# Taking out the trash
rm(perceptualMeasures, epsilon)
```

### Priors
First, we need to figure out the model parameters
```{r}
modelFormula_AP <- 
  AP ~ Severity*condition + 
    (1 | StudyID) +
    (1 | ListenerID)

brms::get_prior(
  modelFormula_AP,
  data = data_modelData_AP,
  family = Beta
)
```

Now we can specify weakly informative priors.
```{r}
prior_AP <- c(
  prior(normal(0, 10), class = Intercept),
  prior(normal(0, 10), class = b),
  prior(cauchy(0, 10), class = sd),
  prior(gamma(1, 0.5), class = phi) # Phi = 1, mu = .5
)
```

### Building the model
```{r}
model_AP <- brms::brm(
  formula = modelFormula_AP,
  data = data_modelData_AP,
  prior = prior_AP,
  family = Beta,
  chains = 4,
  cores = 4,
  iter = 4000,
  warmup = 1000,
  control = list(adapt_delta = 0.95),
  file = "Models/brms_AP.rds",
  file_refit = "on_change"
)


# Calculating the residual variance
if (file.exists("Models/variance_AP.rds") == T) {
  variance_AP <- base::readRDS(file = "Models/variance_AP.rds")
} else {
  variance_AP <- insight::get_variance(model_AP)
  base::saveRDS(variance_AP, file = "Models/variance_AP.rds")
}
```

### Model Summary
```{r}
# Probability of direction (pd)
pd_AP <- bayestestR::p_direction(model_AP) %>%
  dplyr::rename(term = Parameter,
                effect = Effects,
                component = Component) %>%
  dplyr::mutate(
    component = ifelse(component == "conditional", "cond", component),
    term = gsub(pattern = "b_", replacement = "", term),
    term = ifelse(term == "Intercept", "(Intercept)", term))

# Model results
modelSummary_AP <- tidy(model_AP) %>%
  dplyr::rename(l_95_CI = conf.low,
                u_95_CI = conf.high) %>%
  dplyr::mutate(order = row_number()) %>%
  base::merge(.,pd_AP, all = T) %>%
  dplyr::arrange(order) %>%
  dplyr::select(!order) %>%
  dplyr::mutate(
    robust = case_when(
      as.integer(!(l_95_CI <= 0 & u_95_CI > 0)) == 1 & pd > .95 ~ "robust",
      TRUE ~ "not robust"
    )
  )

rm(pd_AP)
```

### Pairwise Comparisons
```{r}

# Probability of direction (pd)
pd_emmeans_AP <- bayestestR::p_direction(
  model_AP %>%
    emmeans::emmeans(
      ~ condition | Severity,
      epred = TRUE,
      re_formula = NA,
    ) %>%
    emmeans::contrast(method = "revpairwise")
) |>
  as.data.frame() %>%
  dplyr::mutate(Severity = gsub(pattern = "moreClear - conv ", replacement = "", Parameter)) %>%
  as.data.frame() |>
  dplyr::select(!Parameter)


emmeans_AP <- model_AP %>%
  emmeans::emmeans(~ condition | Severity,
                   epred = TRUE,
                   re_formula = NA,) %>%
  emmeans::contrast(method = "revpairwise") %>%
  tidy() |>
  dplyr::rename(l_95_HPD = lower.HPD,
                u_95_HPD = upper.HPD) %>%
  dplyr::mutate(order = row_number()) %>%
  base::merge(., pd_emmeans_AP) |>
  dplyr::arrange(order) %>%
  dplyr::select(!order) %>%
  dplyr::mutate(
    robust = case_when(
      as.integer(!(l_95_HPD <= 0 & u_95_HPD > 0)) == 1 & pd > .95 ~ "robust",
      TRUE ~ "not robust"
    ),
    writeUp = paste0("β=",rd(estimate, digits = 2),", 95% HPD Interval = [",
                     rd(l_95_HPD, digits = 2), ", ",
                     rd(u_95_HPD, digits = 2), "]")
  )

rm(pd_emmeans_AP)
```
### Model Diagnostics
```{r}
# Assess chain mixing
plot_chainMix_AP <- base::plot(model_AP, ask=FALSE)

# Posterior predictive check
plot_ppCheck_AP <- brms::pp_check(model_AP, ndraws = 1000)

# Plot conditional effects
plot_conditionalEffects_AP <- base::plot(conditional_effects(model_AP), ask = FALSE)

# APerval Estimations
data_posterior_AP <- as.matrix(model_AP) %>%
  as.data.frame()

plot_intervalEst_AP <- mcmc_areas(
  data_posterior_AP,
  pars = fixed_effects <- data_posterior_AP %>%
    as.data.frame() %>%
    dplyr::select(starts_with("b_")) %>%
    colnames(),
  # arbitrary threshold for shading probability mass
  prob = 0.95
) 

```

## aVSA
Acoustic Vowel Space Area (aVSA) is an acoustic measure of articulatory working space. There are known sex differences when aVSA is measured in Hz. Therefore, we will measure it in Bark to try to reduce the sex effects.

The bark transformed aVSA measure ranges from .8 - 18 Bark. So it is a measure bound by 0, with no negative values. For this reason, we will use a lognormal family.
### Loading the data
```{r}
vsaMeasures <- rio::import(file = "https://raw.githubusercontent.com/AustinRThompson/multidomain-vowelArtic-PD/main/Data/PreppedData/CollatedData/TargetMeasures_vsaMeasures.csv") %>%
  dplyr::filter(condition != "lessClear") %>% # We won't use the less clear condition in this study
  
  # Here we rename some variables and clean up the factors
  dplyr::mutate(Sex = factor(Sex, levels = c("M", "F")),
                condition = factor(condition, levels = c("conv", "moreClear"))) %>%
  
  # Now we merge the data with the speakerList, which has information about severity level.
  base::merge(., speakerList %>%
                dplyr::select(StudyID, Severity)) %>%
  dplyr::mutate(
    Severity = factor(
      Severity,
      levels = c("HC", "Mild", "Moderate", "Severe", "Profound"),
      labels = c("Control", "Mild", "Moderate", "Severe", "Profound")
    )
  )

# Lets visualize the outcome measure, aVSA_bark
hist(vsaMeasures$aVSA_bark)

data_modelData_aVSA <- vsaMeasures
performance::check_distribution(data_modelData_aVSA$aVSA_bark)

# Taking out the trash
rm(vsaMeasures)
```

### Priors
First, we need to figure out the model parameters
```{r}
modelFormula_aVSA <- 
  aVSA_bark ~ 
  Severity * condition +
  (1 | StudyID) # Here, we only have one aVSA value per speaker and condition

brms::get_prior(
  formula = modelFormula_aVSA,
  data = data_modelData_aVSA,
  family = lognormal())
```
Now we can specify weakly informative priors.
```{r}
# specify priors in log space
priors_aVSA <- c(
  prior(normal(0, 10), class = Intercept),
  prior(normal(0, 10), class = b),
  prior(cauchy(0, 10), class = sd),
  prior(cauchy(0, 10), class = sigma)
)
```

### Building the model
```{r}

model_aVSA <- brms::brm(
  formula = modelFormula_aVSA,
  data = data_modelData_aVSA,
  family = lognormal(),
  prior = priors_aVSA,
  chains = 4,
  cores = 4,
  iter = 4000,
  warmup = 1000,
  control = list(adapt_delta = 0.95),
  file = "Models/brms_aVSA.rds",
  file_refit = "on_change"
)

# Calculating the residual variance
if (file.exists("Models/variance_aVSA.rds") == T) {
  variance_aVSA <- base::readRDS(file = "Models/variance_aVSA.rds")
} else {
  variance_aVSA <- insight::get_variance(model_aVSA)
  base::saveRDS(variance_aVSA, file = "Models/variance_aVSA.rds")
}
```

### Model Summary
```{r}
# Probability of direction (pd)
pd_aVSA <- bayestestR::p_direction(model_aVSA) %>%
  dplyr::rename(term = Parameter,
                effect = Effects,
                component = Component) %>%
  dplyr::mutate(
    component = ifelse(component == "conditional", "cond", component),
    term = gsub(pattern = "b_", replacement = "", term),
    term = ifelse(term == "Intercept", "(Intercept)", term))

# Model results
modelSummary_aVSA <- tidy(model_aVSA) %>%
  dplyr::rename(l_95_CI = conf.low,
                u_95_CI = conf.high) %>%
  dplyr::mutate(order = row_number()) %>%
  base::merge(.,pd_aVSA, all = T) %>%
  dplyr::arrange(order) %>%
  dplyr::select(!order) %>%
  dplyr::mutate(
    robust = case_when(
      as.integer(!(l_95_CI <= 0 & u_95_CI > 0)) == 1 & pd > .95 ~ "robust",
      TRUE ~ "not robust"
    )
  )

rm(pd_aVSA)
```

### Pairwise Comparisons
```{r}

# Probability of direction (pd)
pd_emmeans_aVSA <- bayestestR::p_direction(
  model_aVSA %>%
    emmeans::emmeans(
      ~ condition | Severity,
      epred = TRUE,
      re_formula = NA,
    ) %>%
    emmeans::contrast(method = "revpairwise")
) |>
  as.data.frame() %>%
  dplyr::mutate(Severity = gsub(pattern = "moreClear - conv ", replacement = "", Parameter)) %>%
  as.data.frame() |>
  dplyr::select(!Parameter)


emmeans_aVSA <- model_aVSA %>%
  emmeans::emmeans(~ condition | Severity,
                   epred = TRUE,
                   re_formula = NA,) %>%
  emmeans::contrast(method = "revpairwise") %>%
  tidy() |>
  dplyr::rename(l_95_HPD = lower.HPD,
                u_95_HPD = upper.HPD) %>%
  dplyr::mutate(order = row_number()) %>%
  base::merge(., pd_emmeans_aVSA) |>
  dplyr::arrange(order) %>%
  dplyr::select(!order) %>%
  dplyr::mutate(
    robust = case_when(
      as.integer(!(l_95_HPD <= 0 & u_95_HPD > 0)) == 1 & pd > .95 ~ "robust",
      TRUE ~ "not robust"
    ),
    writeUp = paste0("β=",rd(estimate, digits = 2),", 95% HPD Interval = [",
                     rd(l_95_HPD, digits = 2), ", ",
                     rd(u_95_HPD, digits = 2), "]")
  )

rm(pd_emmeans_aVSA)
```

### Model Diagnostics
```{r}
# Assess chain mixing
plot_chainMix_aVSA <- base::plot(model_aVSA, ask=FALSE)

# Posterior predictive check
plot_ppCheck_aVSA <- brms::pp_check(model_aVSA, ndraws = 1000)

# Plot conditional effects
plot_conditionalEffects_aVSA <- base::plot(conditional_effects(model_aVSA), ask = FALSE)

# aVSAerval Estimations
data_posterior_aVSA <- as.matrix(model_aVSA) %>%
  as.data.frame()

plot_intervalEst_aVSA <- mcmc_areas(
  data_posterior_aVSA,
  pars = fixed_effects <- data_posterior_aVSA %>%
    as.data.frame() %>%
    dplyr::select(starts_with("b_")) %>%
    colnames(),
  # arbitrary threshold for shading probability mass
  prob = 0.95
) 

```


## Kinematic Distance
Kinematic distance was measured from the tongue back sensor (adhered 5 mm from the tongue tip) during the diphthong /ai/ in "buy". The 2D positions of the onset and offset were used to calculate the Euclidean distance. This measure ranges from 0.03 to 28 mm. So, it is bound by 0, and does not have any negative values. For this reason, we use the lognormal family.
### Loading the data
```{r}
aiMeasures <-
  rio::import(file = "https://raw.githubusercontent.com/AustinRThompson/multidomain-vowelArtic-PD/main/Data/PreppedData/CollatedData/TargetMeasures_aiMeasures.csv") %>%
  dplyr::filter(condition != "lessClear") %>% # We won't use the less clear condition in this study
  
# Here we rename some variables and clean up the factors
  dplyr::mutate(Sex = factor(Sex, levels = c("M", "F")),
                condition = factor(condition, levels = c("conv", "moreClear"))) %>%
  
  # Now we merge the data with the speakerList, which has information about severity level.
  base::merge(., speakerList %>%
                dplyr::select(StudyID, Severity)) %>%
  dplyr::mutate(
    Severity = factor(
      Severity,
      levels = c("HC", "Mild", "Moderate", "Severe", "Profound"),
      labels = c("Control", "Mild", "Moderate", "Severe", "Profound")
    )
  ) %>%
  dplyr::group_by(StudyID, Group, Sex, Severity, condition) %>%
  dplyr::summarise(kinDistance = mean(kinDistance, na.rm = T)) %>%
  dplyr::ungroup()

# Lets visualize the outcome measure, kinDistance
hist(aiMeasures$kinDistance)
hist(log(aiMeasures$kinDistance + 1))

data_modelData_kinDistance <- aiMeasures %>%
  dplyr::mutate(kinDistance = kinDistance + 1) # applying a constant before the log transformation in the model

performance::check_distribution(data_modelData_kinDistance$kinDistance)
hist(log(data_modelData_kinDistance$kinDistance))

# Taking out the trash
rm(aiMeasures)
```

### Priors
First, we need to figure out the model parameters
```{r}

modelFormula_kinDistance <-
  kinDistance ~ Severity * condition +
  (1 | StudyID) # Each Speaker (StudyID) has 2 kinDistance measures for each condition

brms::get_prior(formula = modelFormula_kinDistance,
                data = data_modelData_kinDistance,
                family = lognormal)
```

Now we can specify weakly informative priors.
```{r}
priors_kinDistance <- c(
  prior(normal(0, 10), class = Intercept),
  prior(normal(0, 10), class = b),
  prior(cauchy(0, 10), class = sigma),
  prior(cauchy(0, 10), class = sd)
)
```

### Building the model
```{r}
model_kinDistance <- brms::brm(
  formula = modelFormula_kinDistance,
  data = data_modelData_kinDistance,
  family = lognormal,
  prior = priors_kinDistance,
  chains = 4,
  cores = 4,
  iter = 4000,
  warmup = 1000,
  control = list(adapt_delta = 0.95),
  file = "Models/brms_kinDistance.rds",
  file_refit = "on_change"
)

# Calculating the residual variance
if (file.exists("Models/variance_kinDistance.rds") == T) {
  variance_kinDistance <- base::readRDS(file = "Models/variance_kinDistance.rds")
} else {
  variance_kinDistance <- insight::get_variance(model_kinDistance)
  base::saveRDS(variance_kinDistance, file = "Models/variance_kinDistance.rds")
}
```


### Model Summary
```{r}
# Probability of direction (pd)
pd_kinDistance <- bayestestR::p_direction(model_kinDistance) %>%
  dplyr::rename(term = Parameter,
                effect = Effects,
                component = Component) %>%
  dplyr::mutate(
    component = ifelse(component == "conditional", "cond", component),
    term = gsub(pattern = "b_", replacement = "", term),
    term = ifelse(term == "Intercept", "(Intercept)", term))

# Model results
modelSummary_kinDistance <- tidy(model_kinDistance) %>%
  dplyr::rename(l_95_CI = conf.low,
                u_95_CI = conf.high) %>%
  dplyr::mutate(order = row_number()) %>%
  base::merge(.,pd_kinDistance, all = T) %>%
  dplyr::arrange(order) %>%
  dplyr::select(!order) %>%
  dplyr::mutate(
    robust = case_when(
      as.integer(!(l_95_CI <= 0 & u_95_CI > 0)) == 1 & pd > .95 ~ "robust",
      TRUE ~ "not robust"
    )
  )

rm(pd_kinDistance)
```

### Pairwise Comparisons
```{r}

# Probability of direction (pd)
pd_emmeans_kinDistance <- bayestestR::p_direction(
  model_kinDistance %>%
    emmeans::emmeans(
      ~ condition | Severity,
      epred = TRUE,
      re_formula = NA,
    ) %>%
    emmeans::contrast(method = "revpairwise")
) |>
  as.data.frame() %>%
  dplyr::mutate(Severity = gsub(pattern = "moreClear - conv ", replacement = "", Parameter)) %>%
  as.data.frame() |>
  dplyr::select(!Parameter)


emmeans_kinDistance <- model_kinDistance %>%
  emmeans::emmeans(~ condition | Severity,
                   epred = TRUE,
                   re_formula = NA,) %>%
  emmeans::contrast(method = "revpairwise") %>%
  tidy() |>
  dplyr::rename(l_95_HPD = lower.HPD,
                u_95_HPD = upper.HPD) %>%
  dplyr::mutate(order = row_number()) %>%
  base::merge(., pd_emmeans_kinDistance) |>
  dplyr::arrange(order) %>%
  dplyr::select(!order) %>%
  dplyr::mutate(
    robust = case_when(
      as.integer(!(l_95_HPD <= 0 & u_95_HPD > 0)) == 1 & pd > .95 ~ "robust",
      TRUE ~ "not robust"
    ),
    writeUp = paste0("β=",rd(estimate, digits = 2),", 95% HPD Interval = [",
                     rd(l_95_HPD, digits = 2), ", ",
                     rd(u_95_HPD, digits = 2), "]")
  )

rm(pd_emmeans_kinDistance)
```

### Model Diagnostics
```{r}
# Assess chain mixing
plot_chainMix_kinDistance <- base::plot(model_kinDistance, ask=FALSE)

# Posterior predictive check
plot_ppCheck_kinDistance <- brms::pp_check(model_kinDistance, ndraws = 1000)

# Plot conditional effects
plot_conditionalEffects_kinDistance <- base::plot(conditional_effects(model_kinDistance), ask = FALSE)

# kinDistanceerval Estimations
data_posterior_kinDistance <- as.matrix(model_kinDistance) %>%
  as.data.frame()

plot_intervalEst_kinDistance <- mcmc_areas(
  data_posterior_kinDistance,
  pars = fixed_effects <- data_posterior_kinDistance %>%
    as.data.frame() %>%
    dplyr::select(starts_with("b_")) %>%
    colnames(),
  # arbitrary threshold for shading probability mass
  prob = 0.95
) 

```

## Kinematic Distance + Duration
Kinematic distance was measured from the tongue back sensor (adhered 5 mm from the tongue tip) during the diphthong /ai/ in "buy". The 2D positions of the onset and offset were used to calculate the Euclidean distance. This measure ranges from 0.03 to 28 mm. So, it is bound by 0, and does not have any negative values. For this reason, we use the lognormal family.
### Loading the data
```{r}
aiMeasures <-
  rio::import(file = "https://raw.githubusercontent.com/AustinRThompson/multidomain-vowelArtic-PD/main/Data/PreppedData/CollatedData/TargetMeasures_aiMeasures.csv") %>%
  dplyr::filter(condition != "lessClear") %>% # We won't use the less clear condition in this study
  
# Here we rename some variables and clean up the factors
  dplyr::mutate(Sex = factor(Sex, levels = c("M", "F")),
                condition = factor(condition, levels = c("conv", "moreClear"))) %>%
  
  # Now we merge the data with the speakerList, which has information about severity level.
  base::merge(., speakerList %>%
                dplyr::select(StudyID, Severity)) %>%
  dplyr::mutate(
    Severity = factor(
      Severity,
      levels = c("HC", "Mild", "Moderate", "Severe", "Profound"),
      labels = c("Control", "Mild", "Moderate", "Severe", "Profound")
    )
  ) %>%
  dplyr::group_by(StudyID, Group, Sex, Severity, condition) %>%
  dplyr::summarise(kinDistance = mean(kinDistance, na.rm = T),
                   duration = mean(duration, na.rm = T)) %>%
  dplyr::ungroup()

# Lets visualize the outcome measure, kinDistance
hist(aiMeasures$kinDistance)
hist(log(aiMeasures$kinDistance + 1))

data_modelData_kinDistance <- aiMeasures %>%
  dplyr::mutate(kinDistance = kinDistance + 1) # applying a constant before the log transformation in the model

performance::check_distribution(data_modelData_kinDistance$kinDistance)
hist(log(data_modelData_kinDistance$kinDistance))

# Taking out the trash
rm(aiMeasures)
```

### Priors
First, we need to figure out the model parameters
```{r}

modelFormula_kinDistance <-
  kinDistance ~ Severity * condition + duration +
  (1 | StudyID) # Each Speaker (StudyID) has 2 kinDistance measures for each condition

brms::get_prior(formula = modelFormula_kinDistance,
                data = data_modelData_kinDistance,
                family = lognormal)
```

Now we can specify weakly informative priors.
```{r}
priors_kinDistance <- c(
  prior(normal(0, 10), class = Intercept),
  prior(normal(0, 10), class = b),
  prior(cauchy(0, 10), class = sigma),
  prior(cauchy(0, 10), class = sd)
)
```

### Building the model
```{r}
model_kinDistance <- brms::brm(
  formula = modelFormula_kinDistance,
  data = data_modelData_kinDistance,
  family = lognormal,
  prior = priors_kinDistance,
  chains = 4,
  cores = 4,
  iter = 4000,
  warmup = 1000,
  control = list(adapt_delta = 0.95),
  file = "Models/brms_kinDistance_duration.rds",
  file_refit = "on_change"
)

# Calculating the residual variance
if (file.exists("Models/variance_kinDistance_duration.rds") == T) {
  variance_kinDistance <- base::readRDS(file = "Models/variance_kinDistance_duration.rds")
} else {
  variance_kinDistance <- insight::get_variance(model_kinDistance)
  base::saveRDS(variance_kinDistance, file = "Models/variance_kinDistance_duration.rds")
}
```


### Model Summary
```{r}
# Probability of direction (pd)
pd_kinDistance <- bayestestR::p_direction(model_kinDistance) %>%
  dplyr::rename(term = Parameter,
                effect = Effects,
                component = Component) %>%
  dplyr::mutate(
    component = ifelse(component == "conditional", "cond", component),
    term = gsub(pattern = "b_", replacement = "", term),
    term = ifelse(term == "Intercept", "(Intercept)", term))

# Model results
modelSummary_kinDistance <- tidy(model_kinDistance) %>%
  dplyr::rename(l_95_CI = conf.low,
                u_95_CI = conf.high) %>%
  dplyr::mutate(order = row_number()) %>%
  base::merge(.,pd_kinDistance, all = T) %>%
  dplyr::arrange(order) %>%
  dplyr::select(!order) %>%
  dplyr::mutate(
    robust = case_when(
      as.integer(!(l_95_CI <= 0 & u_95_CI > 0)) == 1 & pd > .95 ~ "robust",
      TRUE ~ "not robust"
    )
  )

rm(pd_kinDistance)
```
### Model Diagnostics
```{r}
# Assess chain mixing
plot_chainMix_kinDistance <- base::plot(model_kinDistance, ask=FALSE)

# Posterior predictive check
plot_ppCheck_kinDistance <- brms::pp_check(model_kinDistance, ndraws = 1000)

# Plot conditional effects
plot_conditionalEffects_kinDistance <- base::plot(conditional_effects(model_kinDistance), ask = FALSE)

# kinDistanceerval Estimations
data_posterior_kinDistance <- as.matrix(model_kinDistance) %>%
  as.data.frame()

plot_intervalEst_kinDistance <- mcmc_areas(
  data_posterior_kinDistance,
  pars = fixed_effects <- data_posterior_kinDistance %>%
    as.data.frame() %>%
    dplyr::select(starts_with("b_")) %>%
    colnames(),
  # arbitrary threshold for shading probability mass
  prob = 0.95
) 

```

# Model Tables
```{r}
summaryTable_fixed <- base::merge(
  
  modelSummary_Int %>%
    dplyr::filter(effect == "fixed") %>%
    dplyr::select(term,
                  Int_estimate = estimate,
                  Int_l_95_CI = l_95_CI,
                  Int_u_95_CI = u_95_CI,
                  Int_pd = pd,
                  Int_robust = robust) %>%
    dplyr::mutate(term = as.factor(term)),
  
  modelSummary_AP %>%
    dplyr::filter(effect == "fixed") %>%
    dplyr::select(term,
                  AP_estimate = estimate,
                  AP_l_95_CI = l_95_CI,
                  AP_u_95_CI = u_95_CI,
                  AP_pd = pd,
                  AP_robust = robust) %>%
    dplyr::mutate(term = as.factor(term))) %>%
  
  base::merge(
    .,
    modelSummary_aVSA %>%
      dplyr::filter(effect == "fixed") %>%
      dplyr::select(
        term,
        aVSA_estimate = estimate,
        aVSA_l_95_CI = l_95_CI,
        aVSA_u_95_CI = u_95_CI,
        aVSA_pd = pd,
                  aVSA_robust = robust
      ) %>%
      dplyr::mutate(term = as.factor(term))
  ) %>%
  
  base::merge(
    .,
    modelSummary_kinDistance %>%
      dplyr::filter(effect == "fixed") %>%
      dplyr::select(
        term,
        kinDistance_estimate = estimate,
        kinDistance_l_95_CI = l_95_CI,
        kinDistance_u_95_CI = u_95_CI,
        kinDistance_pd = pd,
                  kinDistance_robust = robust
      ) %>%
      dplyr::mutate(term = as.factor(term))
  ) %>%
  
  # Making the terms prettier
  dplyr::mutate(
    Int_CI_95 = paste0(
      round(Int_l_95_CI, digits = 2), " – ",
      round(Int_u_95_CI, digits = 2)
    ),
    AP_CI_95 = paste0(
      round(AP_l_95_CI, digits = 2), " – ",
      round(AP_u_95_CI, digits = 2)),
    aVSA_CI_95 = paste0(
      round(aVSA_l_95_CI, digits = 2), " – ",
      round(aVSA_u_95_CI, digits = 2)
    ),
    kinDistance_CI_95 = paste0(
      round(kinDistance_l_95_CI, digits = 2), " – ",
      round(kinDistance_u_95_CI, digits = 2)
    ),
    
    terms = factor(
      term,
      levels = c(
        "(Intercept)",
        "SeverityMild",
        "SeverityModerate",
        "SeveritySevere",
        "SeverityProfound",
        "conditionmoreClear",
        "SeverityMild:conditionmoreClear",
        "SeverityModerate:conditionmoreClear",
        "SeveritySevere:conditionmoreClear",
        "SeverityProfound:conditionmoreClear"
      ),
      labels = c(
        "Intercept (Control × Conversational)",
        "Mild × Conversational",
        "Moderate × Conversational",
        "Severe × Conversational",
        "Profound × Conversational",
        "Control × Clear",
        "Mild × Clear",
        "Moderate × Clear",
        "Severe × Clear",
        "Profound × Clear"
      ),
    )) %>% 
  dplyr::relocate(terms, .after = term) %>%
  arrange(terms)


summaryTable_fixed %>%
  dplyr::select(!c(term,
                Int_l_95_CI, Int_u_95_CI,
                AP_l_95_CI, AP_u_95_CI,
                aVSA_l_95_CI, aVSA_u_95_CI,
                kinDistance_l_95_CI, kinDistance_u_95_CI)) %>%
  gt::gt() |>
  gt::tab_spanner(
    columns = c(Int_estimate,
               Int_CI_95,
               Int_pd),
    label = "Intelligibility"
  ) |>
  gt::tab_spanner(
    columns = c(AP_estimate,
               AP_CI_95,
               AP_pd),
    label = "Articulatory Precision"
  ) |>
  gt::tab_spanner(
    columns = c(aVSA_estimate,
               aVSA_CI_95,
               aVSA_pd),
    label = "Vowel Space Area"
  ) |>
  gt::tab_spanner(
    columns = c(kinDistance_estimate,
               kinDistance_CI_95,
               kinDistance_pd),
    label = "Kinematic Distance"
  ) |>
  gt::fmt_number(columns = Int_estimate:kinDistance_pd,
                 decimals = 2) |>
  gt::fmt_percent(columns = c(Int_pd,
                             AP_pd,
                             aVSA_pd,
                             kinDistance_pd), ) |>
  gt::cols_label(
    terms = "Predictors",
    Int_estimate = "Estimates",
    AP_estimate = "Estimates",
    aVSA_estimate = "Estimates",
    kinDistance_estimate = "Estimates",
    Int_CI_95 = "CI (95%)",
    AP_CI_95 = "CI (95%)",
    aVSA_CI_95 = "CI (95%)",
    kinDistance_CI_95 = "CI (95%)",
    Int_pd = "pd",
    AP_pd = "pd",
    aVSA_pd = "pd",
    kinDistance_pd = "pd",
  ) %>%
  gt::cols_align(align = "left",
                 columns = terms) |>
  # Bolding for robust effects
  ## Intelligibility
  gt::tab_style(
    style = list(gt::cell_text(weight = "bold")),
    locations = gt::cells_body(columns = c(Int_estimate,
                                           Int_CI_95,
                                           Int_pd),
                               rows = Int_robust == "robust")
  ) |> 
  ## Articulatory precision
  gt::tab_style(
    style = list(gt::cell_text(weight = "bold")),
    locations = gt::cells_body(columns = c(AP_estimate,
                                           AP_CI_95,
                                           AP_pd),
                               rows = AP_robust == "robust")
  ) |> 
  ## aVSA
  gt::tab_style(
    style = list(gt::cell_text(weight = "bold")),
    locations = gt::cells_body(columns = c(aVSA_estimate,
                                           aVSA_CI_95,
                                           aVSA_pd),
                               rows = aVSA_robust == "robust")
  ) |> 
  ## Kinematic Distance
  gt::tab_style(
    style = list(gt::cell_text(weight = "bold")),
    locations = gt::cells_body(columns = c(kinDistance_estimate,
                                           kinDistance_CI_95,
                                           kinDistance_pd),
                               rows = kinDistance_robust == "robust")
  ) |> 
  gt::cols_hide(
    columns = c(Int_robust,
                AP_robust,
                aVSA_robust,
                kinDistance_robust)
  ) |>
  
  gt::gtsave(filename = "Tables/brmsModel_FixedEffects.html")

summaryTable_random <- data.frame(
  randomEffect = c("σ^2",
                   "N_StudyID",
                   "N_ListenerID",
                   "Observations"),
  Int = c(
    format(round(variance_Int$var.residual, 3), nsmall = 3),
    summary(model_Int)[["ngrps"]][["StudyID"]],
    summary(model_Int)[["ngrps"]][["ListenerID"]],
    summary(model_Int)[["nobs"]]
  ),
  AP = c(
    format(round(variance_AP$var.residual, 3), nsmall = 3),
    summary(model_AP)[["ngrps"]][["StudyID"]],
    summary(model_AP)[["ngrps"]][["ListenerID"]],
    summary(model_AP)[["nobs"]]
  ),
  aVSA = c(
    format(round(variance_aVSA$var.residual, 3), nsmall = 3),
    summary(model_aVSA)[["ngrps"]][["StudyID"]],
    "",
    summary(model_aVSA)[["nobs"]]
  ),
  kinDistance = c(
    format(round(variance_kinDistance$var.residual, 3), nsmall = 3),
    summary(model_kinDistance)[["ngrps"]][["StudyID"]],
    "",
    summary(model_kinDistance)[["nobs"]]
  )
) |>
  gt::gt() |>
  gt::gtsave(filename = "Tables/brmsModel_RandomEffects.html")

```

